{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Айтем2айтем модель на основе implicit и матрицы нормированных каунтов продуктов \n",
    "\n",
    "- взвешенных экпоненциально по времени и обычных\n",
    "\n",
    "01.02.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:15:32.988164Z",
     "start_time": "2020-02-01T15:15:32.681701Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse.linalg import norm\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import (\n",
    "    filter_user_item_pairs,\n",
    "    get_user_item_matrix,\n",
    "    normalized_average_precision\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем юзер-айтем матрицу используя взвешенные по врмени каунты\n",
    "- user_items_02_01_1 exp weight\n",
    "- user_items_02_01_2 exp weight + fix 1./cnt_trans\n",
    "- user_items_02_01_3 обычные каунты 1/cnt_trans (удаляем клиентов из check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:04:22.709470Z",
     "start_time": "2020-02-01T15:04:22.691232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "check_clients = [\n",
    "    '001e840150', '00078c508d', '0008b2cb41', '00035a21d9', '0015aa77ce',\n",
    "    '00184e8b0a', '000f3b9860', '001c2b565f', '000b0559be', '0016b0d9ad',\n",
    "    '000a400848', '000940f00a', '000d599743', '00211fcfaa', '002283ef29',\n",
    "    '001b8d6788', '00071890c8', '0007b4ca21', '000ddb6229', '0006b9ad75',\n",
    "    '00042a927a', '00213be6fb', '0012d1d4aa', '00209f873d', '00184aab1b',\n",
    "    '000702109b', '00031cbbe6', '001175d51b', '000bc820f6', '001c8984f0',\n",
    "    '0010f1f8ca', '0009e6bafa', '000c049a1a', '0007667c60', '000ca87889',\n",
    "    '00020e7b18', '001fb70769', '001566f916', '00010925a5', '001de90d21',\n",
    "    '000efde438', '001392b297', '00134e091b', '0001f552b0', '00167a61e2',\n",
    "    '000df9078a', '0018d2efac', '00047b3720', '00083b5b14', '0021e07838',\n",
    "    '000c216adb', '001a2412c6', '0004315e57', '0019a16b6b', '000990be82',\n",
    "    '0019fb86cb', '00184f3b10', '0010082ab3', '001dac232d', '0019ca361b',\n",
    "    '0017fdd057', '000b9905d8', '0006fca4bf', '00140e5d34', '001d642f66',\n",
    "    '001cef2991', '000bf8ff33', '00127b29bb', '0019e0f07d', '001c25b9e3',\n",
    "    '000a9d12ff', '001f46aa2c', '000b45b7ac', '0018650c30', '0008244fb3',\n",
    "    '0002ce2217', '00174b3561', '0004254599', '00068fd5dc', '001162084a',\n",
    "    '000220a0a7', '000a00419c', '000bd5f2f1', '000012768d', '00022fd34f',\n",
    "    '0018dea0ba', '0004e1e14e', '001d004e5e', '0004231e2a', '000bc94494',\n",
    "    '00184df0c9', '000036f903', '0006f24465', '000ac12729', '0013c0cbab',\n",
    "    '00177cee3e', '0020f90a83', '00065f11c7', '000f46bbfc', '00038f9200',\n",
    "    '0017a7ebcb']\n",
    "print(len(check_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:07:52.158370Z",
     "start_time": "2020-02-01T15:05:19.141323Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:10, 1985.97it/s]\n",
      "20000it [00:10, 1974.05it/s]\n",
      "20000it [00:10, 1936.72it/s]\n",
      "20000it [00:10, 1971.28it/s]\n",
      "20000it [00:10, 1913.18it/s]\n",
      "20000it [00:09, 2070.32it/s]\n",
      "20000it [00:10, 1948.74it/s]\n",
      "20000it [00:10, 1974.09it/s]\n",
      "20000it [00:11, 1804.11it/s]\n",
      "20000it [00:09, 2008.36it/s]\n",
      "162it [00:00, 1945.86it/s]\n",
      "20000it [00:10, 1969.98it/s]\n",
      "20000it [00:09, 2046.40it/s]\n",
      "20000it [00:10, 1944.00it/s]\n",
      "20000it [00:10, 1975.66it/s]\n",
      "20000it [00:10, 1933.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18859795 40510 281079\n",
      "CPU times: user 2min 34s, sys: 2.34 s, total: 2min 37s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_time = datetime.strptime('2019-03-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "valid_chunks = [\n",
    "    '../_processed_data/client_tr_history_4.tsv', \n",
    "    '../_processed_data/client_tr_history_0.tsv',\n",
    "    '../_processed_data/client_tr_history_15.tsv', \n",
    "    '../_processed_data/client_tr_history_16.tsv', \n",
    "    '../_processed_data/client_tr_history_6.tsv'\n",
    "]\n",
    "\n",
    "train_chunks = sorted(glob.glob('../_processed_data/client_tr_history_*'))\n",
    "train_chunks = [chunk for chunk in train_chunks if chunk not in valid_chunks]\n",
    "\n",
    "product_cnt = defaultdict(int)\n",
    "client_cnt = defaultdict(int)\n",
    "client_product = defaultdict(float)\n",
    "\n",
    "for chunk_file in train_chunks:\n",
    "    with open(chunk_file, 'r') as chunk:\n",
    "        for row in tqdm(chunk):\n",
    "            client_id, transaction_history = row.split('\\t')\n",
    "            client_id, transaction_history = json.loads(client_id), json.loads(transaction_history)\n",
    "            \n",
    "            # drop clients from check file\n",
    "            if client_id in check_clients:\n",
    "                continue\n",
    "                \n",
    "            # tr history: dict -> list and sort it\n",
    "            tr_history = [transaction_history[tr] for tr in transaction_history \\\n",
    "                          if datetime.strptime(\n",
    "                                transaction_history[tr]['datetime'], '%Y-%m-%d %H:%M:%S'\n",
    "                             ) < valid_time]\n",
    "            sorted_transactions = sorted(tr_history, \n",
    "                                         key=lambda x: datetime.strptime(x['datetime'], '%Y-%m-%d %H:%M:%S'))\n",
    "            cnt_trans = len(sorted_transactions)\n",
    "            \n",
    "            if cnt_trans > 1:\n",
    "                last_tr_dt = datetime.strptime(sorted_transactions[-1]['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "                first_tr_dt = datetime.strptime(sorted_transactions[0]['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "                coef1 = (valid_time - first_tr_dt).days + 1\n",
    "                coef2 = (valid_time - last_tr_dt).days\n",
    "\n",
    "                for transaction in sorted_transactions:\n",
    "                    tr_dt = datetime.strptime(transaction['datetime'], '%Y-%m-%d %H:%M:%S')\n",
    "                    cur_days_diff = (valid_time - tr_dt).days\n",
    "\n",
    "                    for pr in transaction['products']:\n",
    "                        product_cnt[pr['product_id']] += 1\n",
    "                        client_cnt[client_id] += 1\n",
    "                        client_product[(client_id, pr['product_id'])] += 1./cnt_trans\n",
    "                \n",
    "print(len(client_product), len(product_cnt), len(client_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:09:19.221660Z",
     "start_time": "2020-02-01T15:09:10.426189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18859795 0 2302\n",
      "18857493\n",
      "CPU times: user 8.5 s, sys: 289 ms, total: 8.79 s\n",
      "Wall time: 8.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "item_cnt_threshold = 2 # 02_01_1 02_01_2 02_01_3\n",
    "client_cnt_threshold = 2 # 02_01_1 02_01_2 02_01_3\n",
    "\n",
    "items_to_drop = [pr for pr in product_cnt if product_cnt[pr] < item_cnt_threshold]\n",
    "users_to_drop = [cl for cl in client_cnt if client_cnt[cl] < client_cnt_threshold]\n",
    "\n",
    "client_product_filtered = filter_user_item_pairs(client_product, users_to_drop, items_to_drop)\n",
    "print(len(client_product), len(users_to_drop), len(items_to_drop))\n",
    "print(len(client_product_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:09:59.967259Z",
     "start_time": "2020-02-01T15:09:44.997202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281079 38208 (281079, 38208)\n",
      "CPU times: user 14.8 s, sys: 158 ms, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_index, item_index, user_items = get_user_item_matrix(client_product_filtered, data_format='cnt')\n",
    "print(len(user_index), len(item_index), user_items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:11:10.878556Z",
     "start_time": "2020-02-01T15:11:10.568683Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../_model_files/user_index_02_01_3.pckl', 'wb') as f:\n",
    "    pickle.dump(user_index, f)\n",
    "with open('../_model_files/item_index_02_01_3.pckl', 'wb') as f:\n",
    "    pickle.dump(item_index, f)\n",
    "with open('../_model_files/user_items_02_01_3.pckl', 'wb') as f:\n",
    "    pickle.dump(user_items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем юзер-айтем матрицу, обучаем модель, проверка на check_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:11:51.810276Z",
     "start_time": "2020-02-01T15:11:51.575479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281079 38208 (281079, 38208)\n",
      "38208\n"
     ]
    }
   ],
   "source": [
    "with open('../_model_files/user_index_02_01_3.pckl', 'rb') as f:\n",
    "    user_index = pickle.load(f)\n",
    "with open('../_model_files/item_index_02_01_3.pckl', 'rb') as f:\n",
    "    item_index = pickle.load(f)\n",
    "with open('../_model_files/user_items_02_01_3.pckl', 'rb') as f:\n",
    "    user_items = pickle.load(f)\n",
    "\n",
    "print(len(user_index), len(item_index), user_items.shape)\n",
    "\n",
    "index_item = {v:k for k,v in item_index.items()}\n",
    "print(len(index_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:12:00.289287Z",
     "start_time": "2020-02-01T15:11:55.581126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b46827d84a84cd586327428ee8c05a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.1 s, sys: 150 ms, total: 11.3 s\n",
      "Wall time: 4.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model = implicit.nearest_neighbours.CosineRecommender(K=1)\n",
    "model = implicit.nearest_neighbours.TFIDFRecommender(K=1)\n",
    "model.fit(user_items.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:13:40.249045Z",
     "start_time": "2020-02-01T15:13:40.161240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:00, 1301.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11239912021260304\n",
      "CPU times: user 82.1 ms, sys: 199 µs, total: 82.3 ms\n",
      "Wall time: 80.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ap_values = []\n",
    "queryset_file = '../retailhero-recommender-v2/data/check_queries.tsv'\n",
    "num_items = len(item_index)\n",
    "baseline_items = [\n",
    "    '4009f09b04', '15ccaa8685', 'bf07df54e1', '3e038662c0', '4dcf79043e',\n",
    "    'f4599ca21a', '5cb93c9bc5', '4a29330c8d', '439498bce2', '343e841aaa',\n",
    "    '0a46068efc', 'dc2001d036', '31dcf71bbd', '5645789fdf', '113e3ace79',\n",
    "    'f098ee2a85', '53fc95e177', '080ace8748', '4c07cb5835', 'ea27d5dc75',\n",
    "    'cbe1cd3bb3', '1c257c1a1b', 'f5e18af323', '5186e12ff4', '6d0f84a0ac',\n",
    "    'f95785964a', 'ad865591c6', 'ac81544ebc', 'de25bccdaf', 'f43c12d228',\n",
    "]\n",
    "\n",
    "with open(queryset_file) as fin:\n",
    "    for line in tqdm(fin):        \n",
    "        query_data, next_transaction = line.strip().split('\\t')\n",
    "        query_data, next_transaction = json.loads(query_data), json.loads(next_transaction)\n",
    "        \n",
    "        transaction_history = query_data['transaction_history']\n",
    "        cnt_trans = len(transaction_history)\n",
    "        #query_dt = datetime.strptime(query_data['query_time'], '%Y-%m-%dT%H:%M:%S')\n",
    "            \n",
    "        if cnt_trans > 1:\n",
    "            sorted_transactions = sorted(transaction_history, \n",
    "                                         key=lambda x: datetime.strptime(x['datetime'], '%Y-%m-%dT%H:%M:%S'))                \n",
    "            user_products = defaultdict(float)\n",
    "            user_vector = np.zeros(shape=(1, num_items), dtype=np.float32)\n",
    "                \n",
    "            #last_tr_dt = datetime.strptime(sorted_transactions[-1]['datetime'], '%Y-%m-%dT%H:%M:%S')\n",
    "            #first_tr_dt = datetime.strptime(sorted_transactions[0]['datetime'], '%Y-%m-%dT%H:%M:%S')\n",
    "            #coef1 = (query_dt - first_tr_dt).days + 1\n",
    "            #coef2 = (query_dt - last_tr_dt).days\n",
    "\n",
    "            for transaction in sorted_transactions:\n",
    "                #tr_dt = datetime.strptime(transaction['datetime'], '%Y-%m-%dT%H:%M:%S')\n",
    "                #cur_days_diff = (query_dt - tr_dt).days\n",
    "\n",
    "                for pr in transaction['products']:\n",
    "                    user_products[pr['product_id']] += 1./cnt_trans#np.exp(-(cur_days_diff - coef2)/coef1)/cnt_trans\n",
    "\n",
    "            for pr in user_products:\n",
    "                if pr in item_index:\n",
    "                    user_vector[0, item_index[pr]] = user_products[pr]\n",
    "\n",
    "            raw_recs = model.recommend(userid=0, user_items=csr_matrix(user_vector), N=30, \n",
    "                                       filter_already_liked_items=False, recalculate_user=True)\n",
    "            candidates = [index_item[ind] for (ind, score) in raw_recs]\n",
    "        \n",
    "        else:\n",
    "            candidates = baseline_items.copy()\n",
    "        \n",
    "        ap = normalized_average_precision(next_transaction['product_ids'], candidates)\n",
    "        ap_values.append(ap)\n",
    "        \n",
    "print(sum(ap_values) / len(ap_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разовая валидация на всех валидационных датасетах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T09:20:53.578570Z",
     "start_time": "2020-01-25T09:20:53.551337Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_queries_implicit(model, check_file, item_index, index_item):\n",
    "    \"\"\"\n",
    "    Take implicit model and make recommendations\n",
    "    \"\"\"\n",
    "    ap_values = []\n",
    "    queryset_file = check_file\n",
    "    num_items = len(item_index)\n",
    "\n",
    "    with open(queryset_file) as fin:\n",
    "        for line in tqdm(fin):\n",
    "            user_products = defaultdict(float)\n",
    "            user_vector = np.zeros(shape=(1, num_items))\n",
    "\n",
    "            query_data, next_transaction = line.strip().split('\\t')\n",
    "            query_data, next_transaction = json.loads(query_data), json.loads(next_transaction)\n",
    "            \n",
    "            cnt_trans = len(query_data['transaction_history'])\n",
    "            for transaction in query_data['transaction_history']:\n",
    "                store_id = transaction['store_id']\n",
    "                for pr in transaction['products']:\n",
    "                    if store_id in store_product_cnt:\n",
    "                        if pr['product_id'] in store_product_cnt[store_id]:\n",
    "                            coef = store_product_cnt[store_id][pr['product_id']]\n",
    "                        else:\n",
    "                            coef = 0.\n",
    "                    else:\n",
    "                        coef = 0.\n",
    "                    user_products[pr['product_id']] += 1.*coef/cnt_trans\n",
    "\n",
    "            for pr in user_products:\n",
    "                if pr in item_index:\n",
    "                    user_vector[0, item_index[pr]] = user_products[pr]\n",
    "\n",
    "            raw_recs = model.recommend(userid=0, user_items=csr_matrix(user_vector), N=30, \n",
    "                                       filter_already_liked_items=False, recalculate_user=True)\n",
    "            candidates_product = [index_item[ind] for (ind, score) in raw_recs]\n",
    "\n",
    "            ap = normalized_average_precision(next_transaction['product_ids'], candidates_product)\n",
    "            ap_values.append(ap)  \n",
    "            \n",
    "    return ap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T09:21:50.268216Z",
     "start_time": "2020-01-25T09:20:57.026246Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18877it [00:10, 1751.38it/s]\n",
      "179it [00:00, 1778.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../retailhero-recommender-v2/data/check_queries_01_11_4.tsv\n",
      "0.11725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18874it [00:10, 1818.77it/s]\n",
      "344it [00:00, 1712.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../retailhero-recommender-v2/data/check_queries_01_11_0.tsv\n",
      "0.11596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18918it [00:10, 1751.64it/s]\n",
      "345it [00:00, 1707.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../retailhero-recommender-v2/data/check_queries_01_11_15.tsv\n",
      "0.117526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18883it [00:10, 1781.25it/s]\n",
      "168it [00:00, 1670.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../retailhero-recommender-v2/data/check_queries_01_11_16.tsv\n",
      "0.117919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18904it [00:10, 1771.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../retailhero-recommender-v2/data/check_queries_01_11_6.tsv\n",
      "0.116431\n",
      "\n",
      "*********************\n",
      "Avg score: 0.117018\n",
      "CPU times: user 53.2 s, sys: 173 ms, total: 53.4 s\n",
      "Wall time: 53.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_chunks = [\n",
    "    '../_processed_data/client_tr_history_4.tsv', \n",
    "    '../_processed_data/client_tr_history_0.tsv',\n",
    "    '../_processed_data/client_tr_history_15.tsv', \n",
    "    '../_processed_data/client_tr_history_16.tsv', \n",
    "    '../_processed_data/client_tr_history_6.tsv'\n",
    "]\n",
    "scores = []\n",
    "\n",
    "for chunk_file in valid_chunks:\n",
    "    ind = chunk_file.split('_')[-1].split('.')[0]\n",
    "    valid_file_name = '../retailhero-recommender-v2/data/check_queries_01_11_{num}.tsv'.format(num=ind)\n",
    "    \n",
    "    ap_values = run_queries_implicit(model, valid_file_name, \n",
    "                                     item_index, index_item)\n",
    "    score = sum(ap_values) / len(ap_values)\n",
    "    scores.append(score)\n",
    "    print(valid_file_name)\n",
    "    print(round(score, 6))\n",
    "    \n",
    "print('\\n*********************')\n",
    "print('Avg score:', round(np.mean(scores), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраняем обученную модель для k=1\n",
    "\n",
    "- model_implicit_nn_tfidf_02_01_1 на user_items_02_01_1\n",
    "- model_implicit_nn_tfidf_02_01_2 на user_items_02_01_2\n",
    "- model_implicit_nn_tfidf_02_01_3 на user_items_02_01_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:14:23.153642Z",
     "start_time": "2020-02-01T15:14:18.309870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281079 38208 (281079, 38208)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef9c372d05b4f9fa5ea15fd142c45f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38208), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model trained...\n",
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "# read train data\n",
    "with open('../_model_files/user_index_02_01_3.pckl', 'rb') as f:\n",
    "    user_index = pickle.load(f)\n",
    "with open('../_model_files/item_index_02_01_3.pckl', 'rb') as f:\n",
    "    item_index = pickle.load(f)\n",
    "with open('../_model_files/user_items_02_01_3.pckl', 'rb') as f:\n",
    "    user_items = pickle.load(f)\n",
    "print(len(user_index), len(item_index), user_items.shape)\n",
    "\n",
    "index_item = {v:k for k,v in item_index.items()}\n",
    "\n",
    "model = implicit.nearest_neighbours.TFIDFRecommender(K=1)\n",
    "model.fit(user_items.T)\n",
    "print('model trained...')\n",
    "\n",
    "with open('../_model_files/model_implicit_nn_tfidf_02_01_3.pckl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем tfidf(k=1) на взвешенных каунтах и эвристику\n",
    "\n",
    "- если использвоать user_items_02_01_2, то взвешенные каунты\n",
    "- user_items_02_01_3 - обычные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:16:16.197089Z",
     "start_time": "2020-02-01T15:16:15.974012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281079 38208 (281079, 38208)\n",
      "38208\n",
      "CPU times: user 89.5 ms, sys: 129 ms, total: 219 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('../_model_files/user_index_02_01_3.pckl', 'rb') as f:\n",
    "    user_index = pickle.load(f)\n",
    "with open('../_model_files/item_index_02_01_3.pckl', 'rb') as f:\n",
    "    item_index = pickle.load(f)\n",
    "with open('../_model_files/user_items_02_01_3.pckl', 'rb') as f:\n",
    "    user_items = pickle.load(f)\n",
    "\n",
    "print(len(user_index), len(item_index), user_items.shape)\n",
    "\n",
    "index_item = {v:k for k,v in item_index.items()}\n",
    "print(len(index_item))\n",
    "\n",
    "with open('../_model_files/model_implicit_nn_tfidf_02_01_3.pckl', 'rb') as f:\n",
    "    model_nn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:16:20.208550Z",
     "start_time": "2020-02-01T15:16:20.204147Z"
    }
   },
   "outputs": [],
   "source": [
    "def blend_product_lists(*cands, num_candidates=30):\n",
    "    cnt_dict = defaultdict(int)\n",
    "    for cand in cands:\n",
    "        for ind, pr in enumerate(cand):\n",
    "            cnt_dict[pr] += ind + 1\n",
    "\n",
    "    # add rank for items not any of set\n",
    "    for cand in cands:\n",
    "        cand = set(cand)\n",
    "\n",
    "    for pr in cnt_dict:\n",
    "        for cand in cands:\n",
    "            if pr not in cand:\n",
    "                cnt_dict[pr] += num_candidates\n",
    "\n",
    "    sorted_list = sorted(cnt_dict.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "    return [el[0] for el in sorted_list[:num_candidates]]\n",
    "\n",
    "def get_user_vector(user_products_, item_index_, user_vector_):\n",
    "    user_vector = user_vector_.copy()\n",
    "    \n",
    "    for pr in user_products_:\n",
    "        if pr in item_index_:\n",
    "            user_vector[0, item_index_[pr]] = user_products_[pr]\n",
    "            \n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:18:54.794705Z",
     "start_time": "2020-02-01T15:18:54.671553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:00, 892.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11412069271520268\n",
      "CPU times: user 117 ms, sys: 168 µs, total: 117 ms\n",
      "Wall time: 115 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ap_values = []\n",
    "baseline_items = [\n",
    "    '4009f09b04', '15ccaa8685', 'bf07df54e1', '3e038662c0', '4dcf79043e',\n",
    "    'f4599ca21a', '5cb93c9bc5', '4a29330c8d', '439498bce2', '343e841aaa',\n",
    "    '0a46068efc', 'dc2001d036', '31dcf71bbd', '5645789fdf', '113e3ace79',\n",
    "    'f098ee2a85', '53fc95e177', '080ace8748', '4c07cb5835', 'ea27d5dc75',\n",
    "    'cbe1cd3bb3', '1c257c1a1b', 'f5e18af323', '5186e12ff4', '6d0f84a0ac',\n",
    "    'f95785964a', 'ad865591c6', 'ac81544ebc', 'de25bccdaf', 'f43c12d228',\n",
    "]\n",
    "queryset_file = '../retailhero-recommender-v2/data/check_queries.tsv'\n",
    "num_items = len(item_index)\n",
    "\n",
    "with open(queryset_file) as fin:\n",
    "    for line in tqdm(fin):        \n",
    "        query_data, next_transaction = line.strip().split('\\t')\n",
    "        query_data, next_transaction = json.loads(query_data), json.loads(next_transaction)\n",
    "        \n",
    "        transaction_history = query_data['transaction_history']\n",
    "        cnt_trans = len(transaction_history)\n",
    "        query_dt = datetime.strptime(query_data['query_time'], '%Y-%m-%dT%H:%M:%S')\n",
    "        \n",
    "        if cnt_trans > 1:\n",
    "            sorted_transactions = sorted(transaction_history, \n",
    "                                         key=lambda x: datetime.strptime(x['datetime'], '%Y-%m-%dT%H:%M:%S'))                \n",
    "            # several variants\n",
    "            user_products = defaultdict(float)\n",
    "            user_products_exp = defaultdict(float)\n",
    "            user_vector = np.zeros(shape=(1, num_items), dtype=np.float32)\n",
    "            \n",
    "            # dt features\n",
    "            last_tr_dt = datetime.strptime(sorted_transactions[-1]['datetime'], '%Y-%m-%dT%H:%M:%S')\n",
    "            first_tr_dt = datetime.strptime(sorted_transactions[0]['datetime'], '%Y-%m-%dT%H:%M:%S')\n",
    "            coef1 = (query_dt - first_tr_dt).days + 1\n",
    "            coef2 = (query_dt - last_tr_dt).days\n",
    "\n",
    "            for transaction in sorted_transactions:\n",
    "                tr_dt = datetime.strptime(transaction['datetime'], '%Y-%m-%dT%H:%M:%S')\n",
    "                cur_days_diff = (query_dt - tr_dt).days\n",
    "\n",
    "                for pr in transaction['products']:\n",
    "                    user_products[pr['product_id']] += 1./cnt_trans\n",
    "                    user_products_exp[pr['product_id']] += np.exp(-(cur_days_diff - coef2)/coef1)/cnt_trans\n",
    "\n",
    "            # get model nn candidates\n",
    "            user_vector = get_user_vector(user_products, item_index, user_vector)\n",
    "            raw_recs = model_nn.recommend(userid=0, user_items=csr_matrix(user_vector), N=30, \n",
    "                                       filter_already_liked_items=False, recalculate_user=True)\n",
    "            candidates_nn = [index_item[ind] for (ind, score) in raw_recs]\n",
    "            \n",
    "            # get dummy candidates\n",
    "            ups = sorted(user_products.items(), key=lambda x: x[1], reverse=True)\n",
    "            candidates_dummy = [item[0] for item in ups if item[1] > 1./cnt_trans][:30]\n",
    "            \n",
    "            #ups = sorted(user_products.items(), key=lambda x: x[1], reverse=True)\n",
    "            #candidates_dummy = [item[0] for item in ups if item[1] > 2.][:30]\n",
    "            \n",
    "            candidates_ = [candidates_nn, candidates_dummy]#, candidates_dummy2]\n",
    "            candidates_ = blend_product_lists(*candidates_)\n",
    "            \n",
    "            candidates_set = set(candidates_)\n",
    "            rec_len = len(candidates_)\n",
    "\n",
    "            if rec_len < 30:\n",
    "                items_add = [item for item in baseline_items if item not in candidates_set]\n",
    "                candidates = candidates_ + items_add[:30 - rec_len]\n",
    "            else:\n",
    "                candidates = candidates_.copy()\n",
    "        else:\n",
    "            candidates = baseline_items.copy()   \n",
    "        \n",
    "        ap = normalized_average_precision(next_transaction['product_ids'], candidates)\n",
    "        ap_values.append(ap)\n",
    "        \n",
    "print(sum(ap_values) / len(ap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
