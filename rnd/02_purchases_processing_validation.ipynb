{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраним данные о покупках для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:33:14.334822Z",
     "start_time": "2020-02-01T15:33:14.100274Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Все в один большой словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T14:14:12.686784Z",
     "start_time": "2020-01-11T14:10:34.736751Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45786568it [03:37, 210089.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400162\n",
      "CPU times: user 3min 41s, sys: 7.51 s, total: 3min 49s\n",
      "Wall time: 3min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "purchase_data = {}\n",
    "\n",
    "with open('../../uplift_modeling/retailhero-uplift/data/purchases.csv', ) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in tqdm(reader):\n",
    "        \n",
    "        client_id_cur = row['client_id']\n",
    "        transaction_id_cur = row['transaction_id']\n",
    "        \n",
    "        # create new client if not exists\n",
    "        if client_id_cur not in purchase_data:\n",
    "            purchase_data[client_id_cur] = {}\n",
    "        \n",
    "        # create new transaction if not exists\n",
    "        if transaction_id_cur not in purchase_data[client_id_cur]:\n",
    "            _transaction = {\n",
    "                'datetime': row['transaction_datetime'],\n",
    "                'purchase_sum': row['purchase_sum'],\n",
    "                'store_id': row['store_id'],\n",
    "                'products': []\n",
    "            }\n",
    "            purchase_data[client_id_cur][transaction_id_cur] = _transaction\n",
    "        \n",
    "        # add new product to transaction\n",
    "        product_cur = {\n",
    "            'product_id': row['product_id'],\n",
    "            'quantity' :row['product_quantity']\n",
    "        }\n",
    "        purchase_data[client_id_cur][transaction_id_cur]['products'].append(product_cur)\n",
    "        \n",
    "print(len(purchase_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T14:16:05.070389Z",
     "start_time": "2020-01-11T14:16:05.060496Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7e3e2e3984': {'datetime': '2018-12-01 07:12:45',\n",
       "  'purchase_sum': '1007.0',\n",
       "  'store_id': '54a4a11a29',\n",
       "  'products': [{'product_id': '9a80204f78', 'quantity': '2.0'},\n",
       "   {'product_id': 'da89ebd374', 'quantity': '1.0'},\n",
       "   {'product_id': '0a95e1151d', 'quantity': '1.0'},\n",
       "   {'product_id': '4055b15e4a', 'quantity': '2.0'},\n",
       "   {'product_id': 'a685f1916b', 'quantity': '1.0'},\n",
       "   {'product_id': '21db5dbe53', 'quantity': '1.0'},\n",
       "   {'product_id': '1e208d0b4c', 'quantity': '1.0'},\n",
       "   {'product_id': '15ccaa8685', 'quantity': '1.0'},\n",
       "   {'product_id': '45389bb5b0', 'quantity': '1.0'},\n",
       "   {'product_id': 'cb4c804130', 'quantity': '1.0'},\n",
       "   {'product_id': '7c39f1d12c', 'quantity': '1.0'},\n",
       "   {'product_id': '63e2eac70d', 'quantity': '1.0'},\n",
       "   {'product_id': 'c7cc613e79', 'quantity': '1.0'},\n",
       "   {'product_id': 'ad865591c6', 'quantity': '1.0'},\n",
       "   {'product_id': '7118c66f7f', 'quantity': '1.0'},\n",
       "   {'product_id': 'c55ed13ebd', 'quantity': '1.0'},\n",
       "   {'product_id': '9cdad65286', 'quantity': '1.0'},\n",
       "   {'product_id': '17cf3963fb', 'quantity': '1.0'},\n",
       "   {'product_id': '6bbace0869', 'quantity': '1.0'}]},\n",
       " 'c1ca85d462': {'datetime': '2018-12-16 08:56:01',\n",
       "  'purchase_sum': '574.0',\n",
       "  'store_id': 'ed8d2683fd',\n",
       "  'products': [{'product_id': '4dcf79043e', 'quantity': '4.0'},\n",
       "   {'product_id': 'e6f8ac5174', 'quantity': '1.0'},\n",
       "   {'product_id': '439498bce2', 'quantity': '1.0'},\n",
       "   {'product_id': '9d94b94635', 'quantity': '1.0'},\n",
       "   {'product_id': '32ac3fc229', 'quantity': '1.0'},\n",
       "   {'product_id': '057ea8df98', 'quantity': '1.0'},\n",
       "   {'product_id': '63749d80eb', 'quantity': '1.0'},\n",
       "   {'product_id': '894b4c078d', 'quantity': '1.0'},\n",
       "   {'product_id': 'bd3a2df92d', 'quantity': '1.0'},\n",
       "   {'product_id': 'e4739de8d3', 'quantity': '1.0'},\n",
       "   {'product_id': '1acd9131f6', 'quantity': '1.0'}]},\n",
       " '6a0e96d0bc': {'datetime': '2019-03-08 10:12:03',\n",
       "  'purchase_sum': '803.0',\n",
       "  'store_id': '017c89b915',\n",
       "  'products': [{'product_id': '36294f82c2', 'quantity': '1.0'},\n",
       "   {'product_id': '785b8ca3d3', 'quantity': '1.0'},\n",
       "   {'product_id': '3ca2d19cd3', 'quantity': '0.0'},\n",
       "   {'product_id': 'c55ed13ebd', 'quantity': '1.0'},\n",
       "   {'product_id': 'd41bdf4285', 'quantity': '1.0'},\n",
       "   {'product_id': '25be5dc299', 'quantity': '1.0'},\n",
       "   {'product_id': '32ac3fc229', 'quantity': '1.0'},\n",
       "   {'product_id': '5645789fdf', 'quantity': '1.0'},\n",
       "   {'product_id': 'c4ec937ca8', 'quantity': '1.0'},\n",
       "   {'product_id': '628485eabc', 'quantity': '1.0'},\n",
       "   {'product_id': '30d718e106', 'quantity': '1.0'},\n",
       "   {'product_id': '4b9111aee1', 'quantity': '0.0'},\n",
       "   {'product_id': '24fc3df201', 'quantity': '1.0'},\n",
       "   {'product_id': 'fa8ba5149d', 'quantity': '0.0'},\n",
       "   {'product_id': '2080d1ce9d', 'quantity': '1.0'},\n",
       "   {'product_id': '60d701d7db', 'quantity': '1.0'}]},\n",
       " 'b34f23306e': {'datetime': '2019-03-14 15:01:47',\n",
       "  'purchase_sum': '419.0',\n",
       "  'store_id': '017c89b915',\n",
       "  'products': [{'product_id': '6bab126f22', 'quantity': '1.0'},\n",
       "   {'product_id': 'fa8ba5149d', 'quantity': '0.0'},\n",
       "   {'product_id': '5874d96377', 'quantity': '2.0'},\n",
       "   {'product_id': '63749d80eb', 'quantity': '1.0'},\n",
       "   {'product_id': '057ea8df98', 'quantity': '1.0'},\n",
       "   {'product_id': '15ccaa8685', 'quantity': '1.0'}]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_data['000012768d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраняем большой словарь по чанкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T14:15:17.906660Z",
     "start_time": "2020-01-11T14:14:37.558461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400162/400162 [00:40<00:00, 9919.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 s, sys: 4.36 s, total: 40.4 s\n",
      "Wall time: 40.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunk_size = 20000\n",
    "count = 0\n",
    "chunk_ind = 0\n",
    "file_name = '../_processed_data/client_tr_history_0.tsv'\n",
    "\n",
    "for client_id in tqdm(purchase_data):\n",
    "    \n",
    "    if count == chunk_size:\n",
    "        chunk_ind += 1\n",
    "        file_name = '../_processed_data/client_tr_history_{num}.tsv'.format(num=str(chunk_ind))\n",
    "        count = 0\n",
    "    \n",
    "    chunk_file = open(file_name, 'a')\n",
    "    chunk_file.write(json.dumps(client_id) + '\\t'+ json.dumps(purchase_data[client_id]) + '\\n')\n",
    "    chunk_file.close()\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделяем Клиентов для валидации check_queies_01_11\n",
    "\n",
    "- Подходят те, кто совершал транзации после 2019-03-01\n",
    "- При этом каждая транзакция после 2019-03-01 может быть использована как валидационная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T17:19:36.092980Z",
     "start_time": "2020-01-11T17:18:37.581670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [00:00, 1458.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../_processed_data/client_tr_history_4.tsv', '../_processed_data/client_tr_history_0.tsv', '../_processed_data/client_tr_history_15.tsv', '../_processed_data/client_tr_history_16.tsv', '../_processed_data/client_tr_history_6.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:11, 1703.76it/s]\n",
      "20000it [00:11, 1757.62it/s]\n",
      "20000it [00:11, 1697.25it/s]\n",
      "20000it [00:11, 1700.66it/s]\n",
      "20000it [00:11, 1689.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 1.33 s, total: 58.8 s\n",
      "Wall time: 58.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed = 7777\n",
    "num_chunks_valid = 5\n",
    "valid_time = datetime.strptime('2019-03-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "#valid_time = datetime.strptime('2019-03-02 10:05:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# take several chunks only for validation\n",
    "random.seed(seed)\n",
    "valid_chunks = random.sample(glob.glob('../_processed_data/client_tr_history_*'), k=num_chunks_valid)\n",
    "print(valid_chunks)\n",
    "\n",
    "for chunk_file in valid_chunks:\n",
    "    ind = chunk_file.split('_')[-1].split('.')[0]\n",
    "    valid_file_name = '../_processed_data/check_queries_01_11_{num}.tsv'.format(num=ind)\n",
    "    \n",
    "    with open(chunk_file, 'r') as chunk:\n",
    "        for row in tqdm(chunk):\n",
    "            client_id, transaction_history = row.split('\\t')\n",
    "            client_id, transaction_history = json.loads(client_id), json.loads(transaction_history)\n",
    "            \n",
    "            # tr history: dict -> list and sort it\n",
    "            tr_history = [transaction_history[tr] for tr in transaction_history]\n",
    "            sorted_transactions = sorted(tr_history, key=lambda x: x['datetime'])\n",
    "            \n",
    "            # find candidates for valid transactions, if no - skip iteration\n",
    "            split_candidates = [datetime.strptime(tr['datetime'], '%Y-%m-%d %H:%M:%S') \\\n",
    "                                for tr in sorted_transactions \\\n",
    "                                if datetime.strptime(tr['datetime'], '%Y-%m-%d %H:%M:%S') > valid_time]\n",
    "            if len(split_candidates) == 0:\n",
    "                continue\n",
    "            \n",
    "            # for random split get validation query\n",
    "            split_time = random.choice(split_candidates)\n",
    "            #for split_time in split_candidates:\n",
    "            query_trans_history = [tr for tr in sorted_transactions \n",
    "                                       if datetime.strptime(\n",
    "                                           tr['datetime'], '%Y-%m-%d %H:%M:%S'\n",
    "                                       ) < split_time]\n",
    "            _next_transaction = [tr for tr in sorted_transactions\n",
    "                                  if datetime.strptime(tr['datetime'], '%Y-%m-%d %H:%M:%S') == split_time][0]\n",
    "            next_transaction = {\n",
    "                    'datetime': _next_transaction['datetime'],\n",
    "                    'store_id': _next_transaction['store_id'],\n",
    "                    'purchase_sum': _next_transaction['purchase_sum'],\n",
    "                    'product_ids': [pr['product_id'] for pr in _next_transaction['products']],\n",
    "            }\n",
    "            query = {\n",
    "                    'client_id': client_id,\n",
    "                    'transaction_history': query_trans_history\n",
    "            }\n",
    "                \n",
    "            valid_file = open(valid_file_name, 'a')\n",
    "            valid_file.write(json.dumps(query) + '\\t'+ json.dumps(next_transaction) + '\\n')\n",
    "            valid_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделяем Клиентов для валидации check_queies_02_01\n",
    "\n",
    "- Подходят те, кто совершал транзации после 2019-03-01\n",
    "- При этом каждая транзакция после 2019-03-01 может быть использована как валидационная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:33:17.325393Z",
     "start_time": "2020-02-01T15:33:17.302840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "def dt_format_change(dt):\n",
    "    \"\"\"\n",
    "    '%Y-%m-%d %H:%M:%S' -> '%Y-%m-%dT%H:%M:%S'\n",
    "    \n",
    "    dt: str in '%Y-%m-%d %H:%M:%S'\n",
    "    \"\"\"\n",
    "    return datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "check_clients = [\n",
    "    '001e840150', '00078c508d', '0008b2cb41', '00035a21d9', '0015aa77ce',\n",
    "    '00184e8b0a', '000f3b9860', '001c2b565f', '000b0559be', '0016b0d9ad',\n",
    "    '000a400848', '000940f00a', '000d599743', '00211fcfaa', '002283ef29',\n",
    "    '001b8d6788', '00071890c8', '0007b4ca21', '000ddb6229', '0006b9ad75',\n",
    "    '00042a927a', '00213be6fb', '0012d1d4aa', '00209f873d', '00184aab1b',\n",
    "    '000702109b', '00031cbbe6', '001175d51b', '000bc820f6', '001c8984f0',\n",
    "    '0010f1f8ca', '0009e6bafa', '000c049a1a', '0007667c60', '000ca87889',\n",
    "    '00020e7b18', '001fb70769', '001566f916', '00010925a5', '001de90d21',\n",
    "    '000efde438', '001392b297', '00134e091b', '0001f552b0', '00167a61e2',\n",
    "    '000df9078a', '0018d2efac', '00047b3720', '00083b5b14', '0021e07838',\n",
    "    '000c216adb', '001a2412c6', '0004315e57', '0019a16b6b', '000990be82',\n",
    "    '0019fb86cb', '00184f3b10', '0010082ab3', '001dac232d', '0019ca361b',\n",
    "    '0017fdd057', '000b9905d8', '0006fca4bf', '00140e5d34', '001d642f66',\n",
    "    '001cef2991', '000bf8ff33', '00127b29bb', '0019e0f07d', '001c25b9e3',\n",
    "    '000a9d12ff', '001f46aa2c', '000b45b7ac', '0018650c30', '0008244fb3',\n",
    "    '0002ce2217', '00174b3561', '0004254599', '00068fd5dc', '001162084a',\n",
    "    '000220a0a7', '000a00419c', '000bd5f2f1', '000012768d', '00022fd34f',\n",
    "    '0018dea0ba', '0004e1e14e', '001d004e5e', '0004231e2a', '000bc94494',\n",
    "    '00184df0c9', '000036f903', '0006f24465', '000ac12729', '0013c0cbab',\n",
    "    '00177cee3e', '0020f90a83', '00065f11c7', '000f46bbfc', '00038f9200',\n",
    "    '0017a7ebcb']\n",
    "print(len(check_clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T15:40:05.142502Z",
     "start_time": "2020-02-01T15:38:51.056450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:14, 1339.45it/s]\n",
      "20000it [00:14, 1353.72it/s]\n",
      "20000it [00:14, 1363.03it/s]\n",
      "20000it [00:14, 1342.82it/s]\n",
      "20000it [00:14, 1352.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.28 s, total: 1min 15s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed = 7777\n",
    "num_chunks_valid = 5\n",
    "valid_time = datetime.strptime('2019-03-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "#valid_time = datetime.strptime('2019-03-02 10:05:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# take several chunks only for validation\n",
    "random.seed(seed)\n",
    "valid_chunks = [\n",
    "    '../_processed_data/client_tr_history_4.tsv', \n",
    "    '../_processed_data/client_tr_history_0.tsv',\n",
    "    '../_processed_data/client_tr_history_15.tsv', \n",
    "    '../_processed_data/client_tr_history_16.tsv', \n",
    "    '../_processed_data/client_tr_history_6.tsv'\n",
    "]\n",
    "\n",
    "for chunk_file in valid_chunks:\n",
    "    ind = chunk_file.split('_')[-1].split('.')[0]\n",
    "    valid_file_name = '../_processed_data/check_queries_02_01_{num}.tsv'.format(num=ind)\n",
    "    \n",
    "    with open(chunk_file, 'r') as chunk:\n",
    "        for row in tqdm(chunk):\n",
    "            client_id, transaction_history = row.split('\\t')\n",
    "            client_id, transaction_history = json.loads(client_id), json.loads(transaction_history)\n",
    "            \n",
    "            # drop clients from check file\n",
    "            if client_id in check_clients:\n",
    "                continue\n",
    "                \n",
    "            # tr history: dict -> list and sort it\n",
    "            tr_history = [transaction_history[tr] for tr in transaction_history]\n",
    "            sorted_transactions = sorted(tr_history, key=lambda x: x['datetime'])\n",
    "            \n",
    "            # find candidates for valid transactions, if no - skip iteration\n",
    "            split_candidates = [datetime.strptime(tr['datetime'], '%Y-%m-%d %H:%M:%S') \\\n",
    "                                for tr in sorted_transactions \\\n",
    "                                if datetime.strptime(tr['datetime'], '%Y-%m-%d %H:%M:%S') > valid_time]\n",
    "            if len(split_candidates) == 0:\n",
    "                continue\n",
    "            \n",
    "            # for random split get validation query\n",
    "            split_time = random.choice(split_candidates)\n",
    "            #for split_time in split_candidates:\n",
    "            query_trans_history = [tr for tr in sorted_transactions \n",
    "                                       if datetime.strptime(\n",
    "                                           tr['datetime'], '%Y-%m-%d %H:%M:%S'\n",
    "                                       ) < split_time]\n",
    "            _next_transaction = [tr for tr in sorted_transactions\n",
    "                                  if datetime.strptime(tr['datetime'], '%Y-%m-%d %H:%M:%S') == split_time][0]\n",
    "            # change format of dt\n",
    "            for tr in query_trans_history:\n",
    "                tr['datetime'] = dt_format_change(tr['datetime'])\n",
    "                \n",
    "            next_transaction = {\n",
    "                    'datetime': dt_format_change(_next_transaction['datetime']),\n",
    "                    'store_id': _next_transaction['store_id'],\n",
    "                    'purchase_sum': _next_transaction['purchase_sum'],\n",
    "                    'product_ids': [pr['product_id'] for pr in _next_transaction['products']],\n",
    "            }\n",
    "            query = {\n",
    "                    'client_id': client_id,\n",
    "                    'query_time': dt_format_change(_next_transaction['datetime']),\n",
    "                    'transaction_history': query_trans_history\n",
    "            }\n",
    "                \n",
    "            valid_file = open(valid_file_name, 'a')\n",
    "            valid_file.write(json.dumps(query) + '\\t'+ json.dumps(next_transaction) + '\\n')\n",
    "            valid_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
